"""
RAG Web åº”ç”¨ä¸»ç¨‹åº
åŸºäº Streamlit æ„å»ºçš„é—®ç­”ç•Œé¢
"""

import sys
import os

# ç¡®ä¿ä½¿ç”¨ UTF-8 ç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')

import streamlit as st
from dotenv import load_dotenv

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from rag_engine import (
    load_env,
    split_text,
    split_text_by_strategy,
    embed_texts,
    add_to_vector_db,
    search_top_k,
    generate_answer,
    clear_vector_db,
    get_db_stats,
    add_to_bm25_index,
    search_bm25,
    hybrid_search,
    clear_bm25_index,
    get_bm25_stats,
    sync_bm25_from_vector_db
)
from file_utils import read_file, get_supported_extensions
from chunk_strategy import choose_chunk_strategy, get_strategy_description
from knowledge_graph import extract_knowledge_graph, format_graph_for_prompt, get_graph_stats


def init_session_state():
    """åˆå§‹åŒ– session state"""
    if 'initialized' not in st.session_state:
        st.session_state.initialized = False
    if 'error_message' not in st.session_state:
        st.session_state.error_message = None
    if 'chunk_strategy' not in st.session_state:
        st.session_state.chunk_strategy = None
    if 'chunk_params' not in st.session_state:
        st.session_state.chunk_params = None
    if 'retrieval_mode' not in st.session_state:
        st.session_state.retrieval_mode = 'æ··åˆæ£€ç´¢'


def load_config():
    """åŠ è½½é…ç½®"""
    load_dotenv()
    return {
        "embed_base_url": os.getenv("EMBED_BASE_URL", ""),
        "embed_api_key": os.getenv("EMBED_API_KEY", ""),
        "embed_model": os.getenv("EMBED_MODEL", ""),
        "chat_base_url": os.getenv("CHAT_BASE_URL", ""),
        "chat_api_key": os.getenv("CHAT_API_KEY", ""),
        "chat_model": os.getenv("CHAT_MODEL", "")
    }


def main():
    # é¡µé¢é…ç½®
    st.set_page_config(
        page_title="Web RAG Demo",
        page_icon="âš¡",
        layout="wide"
    )
    
    init_session_state()
    
    # ä¸»æ ‡é¢˜
    st.title("âš¡ Web ç‰ˆ RAGï¼ˆæ”¯æŒå›½å†…å¤§æ¨¡å‹ï¼‰")
    st.markdown("---")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col_left, col_right = st.columns([1, 3])
    
    # ===== å·¦ä¾§æ ï¼šæ¨¡å‹é…ç½® =====
    with col_left:
        st.subheader("ğŸ”§ æ¨¡å‹é…ç½®")
        
        config = load_config()
        
        # æ˜¾ç¤ºå½“å‰é…ç½®çŠ¶æ€
        with st.expander("Embedding é…ç½®", expanded=True):
            st.text_input(
                "Embed Base URL",
                value=config["embed_base_url"],
                disabled=True
            )
            embed_key_display = "å·²é…ç½® âœ…" if config["embed_api_key"] else "æœªé…ç½® âŒ"
            st.text_input("Embed API Key", value=embed_key_display, disabled=True)
            st.text_input("Embed Model", value=config["embed_model"], disabled=True)
        
        with st.expander("Chat é…ç½®", expanded=True):
            st.text_input(
                "Chat Base URL",
                value=config["chat_base_url"],
                disabled=True
            )
            chat_key_display = "å·²é…ç½® âœ…" if config["chat_api_key"] else "æœªé…ç½® âŒ"
            st.text_input("Chat API Key", value=chat_key_display, disabled=True)
            st.text_input("Chat Model", value=config["chat_model"], disabled=True)
        
        # å‘é‡åº“çŠ¶æ€
        st.subheader("ğŸ“Š å‘é‡åº“çŠ¶æ€")
        stats = get_db_stats()
        bm25_stats = get_bm25_stats()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("å‘é‡åº“", stats["total_chunks"])
        with col2:
            st.metric("BM25 ç´¢å¼•", bm25_stats["total_chunks"])
        
        # æ£€æŸ¥åŒæ­¥çŠ¶æ€
        if stats["total_chunks"] != bm25_stats["total_chunks"]:
            diff = abs(stats["total_chunks"] - bm25_stats["total_chunks"])
            st.warning(f"âš ï¸ ç´¢å¼•ä¸åŒæ­¥ï¼ˆå·®å¼‚: {diff} ä¸ªæ–‡æ¡£ï¼‰")
            if st.button("ğŸ”„ åŒæ­¥ BM25 ç´¢å¼•", use_container_width=True, type="primary"):
                with st.spinner("æ­£åœ¨ä»å‘é‡åº“åŒæ­¥åˆ° BM25..."):
                    synced_count = sync_bm25_from_vector_db()
                st.success(f"âœ… åŒæ­¥å®Œæˆï¼å·²åŒæ­¥ {synced_count} ä¸ªæ–‡æ¡£")
                st.rerun()
        else:
            st.success("âœ… ç´¢å¼•å·²åŒæ­¥")
        
        # æ¸…ç©ºæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå‘é‡åº“", use_container_width=True):
                clear_vector_db()
                st.success("å‘é‡åº“å·²æ¸…ç©ºï¼")
                st.rerun()
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º BM25", use_container_width=True):
                clear_bm25_index()
                st.success("BM25 ç´¢å¼•å·²æ¸…ç©ºï¼")
                st.rerun()
        
        # æ£€ç´¢æ¨¡å¼é€‰æ‹©
        st.subheader("ğŸ” æ£€ç´¢æ¨¡å¼")
        retrieval_mode = st.radio(
            "é€‰æ‹©æ£€ç´¢æ–¹å¼",
            ["å‘é‡æ£€ç´¢", "BM25 æ£€ç´¢", "æ··åˆæ£€ç´¢"],
            index=2,
            help="å‘é‡æ£€ç´¢ï¼šè¯­ä¹‰ç†è§£\nBM25ï¼šç²¾ç¡®åŒ¹é…\næ··åˆæ£€ç´¢ï¼šç»¼åˆæœ€ä¼˜ï¼ˆæ¨èï¼‰"
        )
        st.session_state.retrieval_mode = retrieval_mode
        
        # æ··åˆæ£€ç´¢æƒé‡è®¾ç½®
        if retrieval_mode == "æ··åˆæ£€ç´¢":
            vector_weight = st.slider(
                "å‘é‡æ£€ç´¢æƒé‡",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.1,
                help="æƒé‡è¶Šé«˜ï¼Œè¶Šä¾èµ–è¯­ä¹‰ç†è§£ï¼›æƒé‡è¶Šä½ï¼Œè¶Šä¾èµ–ç²¾ç¡®åŒ¹é…"
            )
            st.session_state.vector_weight = vector_weight
            st.caption(f"BM25 æƒé‡: {1-vector_weight:.1f}")
        
        # å½“å‰åˆ‡ç‰‡ç­–ç•¥
        if st.session_state.chunk_strategy:
            st.subheader("ğŸ”€ å½“å‰åˆ‡ç‰‡ç­–ç•¥")
            strategy_desc = get_strategy_description(st.session_state.chunk_strategy)
            st.info(strategy_desc)
            if st.session_state.chunk_params:
                with st.expander("ç­–ç•¥å‚æ•°"):
                    for key, value in st.session_state.chunk_params.items():
                        st.write(f"- **{key}**: {value}")
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        st.subheader("ğŸ“ æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
        for ext in get_supported_extensions():
            st.markdown(f"- `{ext}`")
    
    # ===== å³ä¾§æ ï¼šä¸»åŠŸèƒ½åŒº =====
    with col_right:
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        st.subheader("ğŸ“¤ ä¸Šä¼ æ–‡ä»¶")
        
        uploaded_files = st.file_uploader(
            "é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
            type=["txt", "pdf", "md", "markdown", "jpg", "jpeg", "png"],
            accept_multiple_files=True,
            help="ä¸Šä¼ çš„æ–‡ä»¶å°†è‡ªåŠ¨åˆ‡åˆ†å¹¶å­˜å…¥å‘é‡åº“ï¼ˆå›¾ç‰‡å°†é€šè¿‡ OCR è¯†åˆ«ï¼‰"
        )
        
        if uploaded_files:
            load_env()  # ç¡®ä¿åŠ è½½ç¯å¢ƒå˜é‡
            with st.spinner("æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶..."):
                for uploaded_file in uploaded_files:
                    try:
                        # è¯»å–æ–‡ä»¶å†…å®¹
                        file_content = uploaded_file.read()
                        text = read_file(uploaded_file.name, file_content)
                        
                        if text:
                            # è‡ªåŠ¨é€‰æ‹©åˆ‡ç‰‡ç­–ç•¥
                            strategy, params = choose_chunk_strategy(text)
                            st.session_state.chunk_strategy = strategy
                            st.session_state.chunk_params = params
                            
                            # ä½¿ç”¨ç­–ç•¥åˆ‡åˆ†æ–‡æœ¬
                            chunks = split_text_by_strategy(text, strategy, params)
                            
                            if chunks:
                                # ç”Ÿæˆ embeddings
                                embeddings = embed_texts(chunks)
                                
                                # å­˜å…¥å‘é‡åº“
                                add_to_vector_db(chunks, embeddings)
                                
                                # åŒæ­¥æ·»åŠ åˆ° BM25 ç´¢å¼•
                                add_to_bm25_index(chunks)
                                
                                strategy_desc = get_strategy_description(strategy)
                                st.success(f"âœ… {uploaded_file.name}: æˆåŠŸæ·»åŠ  {len(chunks)} ä¸ª chunksï¼ˆ{strategy_desc}ï¼‰")
                                st.info(f"ğŸ“Š å·²åŒæ­¥åˆ°å‘é‡åº“å’Œ BM25 ç´¢å¼•")
                            else:
                                st.warning(f"âš ï¸ {uploaded_file.name}: æ–‡ä»¶å†…å®¹ä¸ºç©º")
                        else:
                            st.error(f"âŒ {uploaded_file.name}: ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
                    
                    except Exception as e:
                        st.error(f"âŒ {uploaded_file.name}: å¤„ç†å¤±è´¥ - {str(e)}")
        
        # å¯¼å…¥é¢„å¤„ç†æ•°æ®
        st.subheader("ğŸ“¥ å¯¼å…¥é¢„å¤„ç†æ•°æ®")
        imported_file = st.file_uploader(
            "å¯¼å…¥ JSON æ ¼å¼çš„ chunks",
            type=["json"],
            key="import_chunks_file",
            help="æ”¯æŒä» pdf-rag-pipeline å¯¼å‡ºçš„ chunks_for_streamlit.json"
        )
        
        if imported_file:
            import json
            # è¯»å–å¹¶ç¼“å­˜æ–‡ä»¶å†…å®¹
            if 'imported_chunks' not in st.session_state or st.session_state.get('imported_file_name') != imported_file.name:
                try:
                    content = imported_file.read().decode('utf-8')
                    chunks = json.loads(content)
                    if isinstance(chunks, list) and chunks:
                        st.session_state.imported_chunks = chunks
                        st.session_state.imported_file_name = imported_file.name
                        st.info(f"ğŸ“„ å·²åŠ è½½ {len(chunks)} ä¸ª chunksï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å¯¼å…¥")
                    else:
                        st.error("âŒ JSON æ ¼å¼é”™è¯¯ï¼Œéœ€è¦æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨")
                except Exception as e:
                    st.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
            else:
                st.info(f"ğŸ“„ å·²åŠ è½½ {len(st.session_state.imported_chunks)} ä¸ª chunksï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å¯¼å…¥")
            
            if st.button("ğŸš€ å¼€å§‹å¯¼å…¥åˆ°å‘é‡åº“", key="start_import"):
                import time
                chunks = st.session_state.imported_chunks
                load_env()
                
                # åˆ†æ‰¹å¤„ç†ï¼ˆå®åè®¤è¯åæ— é™æµï¼‰
                batch_size = 50
                total_added = 0
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    for i in range(0, len(chunks), batch_size):
                        batch = chunks[i:i+batch_size]
                        status_text.text(f"å¤„ç†ä¸­: {min(i+batch_size, len(chunks))}/{len(chunks)} chunks...")
                        
                        embeddings = embed_texts(batch)
                        add_to_vector_db(batch, embeddings)
                        add_to_bm25_index(batch)
                        total_added += len(batch)
                        
                        progress_bar.progress(min(total_added / len(chunks), 1.0))
                    
                    progress_bar.empty()
                    status_text.empty()
                    # æ¸…é™¤ç¼“å­˜
                    del st.session_state.imported_chunks
                    del st.session_state.imported_file_name
                    st.success(f"âœ… æˆåŠŸå¯¼å…¥ {total_added} ä¸ª chunksï¼ˆå·²åŒæ­¥åˆ°å‘é‡åº“å’Œ BM25 ç´¢å¼•ï¼‰")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}ï¼ˆå·²å¯¼å…¥ {total_added} ä¸ªï¼‰")
        
        st.markdown("---")
        
        # é—®ç­”åŒºåŸŸ
        st.subheader("ğŸ’¬ é—®ç­”åŒºåŸŸ")
        
        # ç”¨æˆ·é—®é¢˜è¾“å…¥
        user_query = st.text_area(
            "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
            placeholder="ä¾‹å¦‚ï¼šè¿™ä¸ªæ–‡æ¡£ä¸»è¦è®²äº†ä»€ä¹ˆå†…å®¹ï¼Ÿ",
            height=100
        )
        
        # æ£€ç´¢æ•°é‡è®¾ç½®
        top_k = st.slider("æ£€ç´¢ Top-K æ•°é‡", min_value=1, max_value=10, value=3)
        
        # çŸ¥è¯†å›¾è°±é€‰é¡¹
        enable_kg = st.checkbox("ğŸ”— å¯ç”¨çŸ¥è¯†å›¾è°±å¢å¼º", value=False, 
                                help="å¯¹æ£€ç´¢ç»“æœè¿›è¡Œå®æ—¶çŸ¥è¯†å›¾è°±æŠ½å–ï¼Œæå‡å¤æ‚é—®é¢˜çš„å›ç­”è´¨é‡")
        
        # ç”Ÿæˆå›ç­”æŒ‰é’®
        if st.button("ğŸš€ ç”Ÿæˆå›ç­”", type="primary", use_container_width=True):
            if not user_query.strip():
                st.warning("è¯·å…ˆè¾“å…¥é—®é¢˜ï¼")
            elif stats["total_chunks"] == 0:
                st.warning("å‘é‡åº“ä¸ºç©ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")
            else:
                try:
                    # åŠ è½½ç¯å¢ƒå˜é‡
                    load_env()
                    
                    with st.spinner("æ­£åœ¨æ£€ç´¢ç›¸å…³å†…å®¹..."):
                        # æ ¹æ®æ£€ç´¢æ¨¡å¼é€‰æ‹©ä¸åŒçš„æ£€ç´¢æ–¹æ³•
                        retrieval_mode = st.session_state.retrieval_mode
                        
                        if retrieval_mode == "å‘é‡æ£€ç´¢":
                            retrieved = search_top_k(user_query, k=top_k)
                        elif retrieval_mode == "BM25 æ£€ç´¢":
                            retrieved = search_bm25(user_query, k=top_k)
                        else:  # æ··åˆæ£€ç´¢
                            vector_weight = st.session_state.get('vector_weight', 0.5)
                            retrieved = hybrid_search(user_query, k=top_k, vector_weight=vector_weight)
                    
                    if not retrieved:
                        st.warning("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                    else:
                        # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
                        st.subheader("ğŸ“š æ£€ç´¢åˆ°çš„çŸ¥è¯†ç‰‡æ®µ")
                        
                        chunks_text = [chunk for chunk, score in retrieved]
                        
                        for i, (chunk, score) in enumerate(retrieved, 1):
                            score_label = "åˆ†æ•°" if retrieval_mode == "BM25 æ£€ç´¢" else "ç›¸ä¼¼åº¦"
                            with st.expander(f"ç‰‡æ®µ {i} ({score_label}: {score:.4f})", expanded=(i == 1)):
                                st.markdown(chunk)
                        
                        # çŸ¥è¯†å›¾è°±æŠ½å–
                        kg_context = ""
                        if enable_kg:
                            try:
                                with st.spinner("æ­£åœ¨æŠ½å–çŸ¥è¯†å›¾è°±..."):
                                    from openai import OpenAI
                                    chat_client = OpenAI(
                                        base_url=os.getenv("CHAT_BASE_URL"),
                                        api_key=os.getenv("CHAT_API_KEY")
                                    )
                                    graph = extract_knowledge_graph(
                                        chunks_text,
                                        chat_client,
                                        os.getenv("CHAT_MODEL", "deepseek-chat")
                                    )
                                    
                                    entities = graph.get("entities", [])
                                    relations = graph.get("relations", [])
                                    
                                    if entities or relations:
                                        kg_context = format_graph_for_prompt(graph)
                                        
                                        # æ˜¾ç¤ºçŸ¥è¯†å›¾è°±
                                        st.subheader("ğŸ”— æŠ½å–çš„çŸ¥è¯†å›¾è°±")
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.markdown("**å®ä½“**")
                                            for e in entities[:8]:
                                                if isinstance(e, dict):
                                                    st.markdown(f"- `{e.get('name', '')}` ({e.get('type', '')})")
                                        with col2:
                                            st.markdown("**å…³ç³»**")
                                            for r in relations[:8]:
                                                if isinstance(r, dict):
                                                    st.markdown(f"- {r.get('source', '')} â†’ {r.get('target', '')}")
                            except Exception as kg_error:
                                st.warning(f"çŸ¥è¯†å›¾è°±æŠ½å–å¤±è´¥: {kg_error}ï¼Œç»§ç»­ä½¿ç”¨æ™®é€šæ£€ç´¢")
                        
                        st.markdown("---")
                        
                        # ç”Ÿæˆç­”æ¡ˆï¼ˆå¸¦çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ï¼‰
                        with st.spinner("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ..."):
                            if kg_context:
                                # å°†çŸ¥è¯†å›¾è°±åŠ å…¥ä¸Šä¸‹æ–‡
                                enhanced_retrieved = [(f"{chunk}\n\n{kg_context}", score) 
                                                     for chunk, score in retrieved[:1]]
                                enhanced_retrieved.extend(retrieved[1:])
                                answer = generate_answer(user_query, enhanced_retrieved)
                            else:
                                answer = generate_answer(user_query, retrieved)
                        
                        # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
                        st.subheader("âœ¨ æœ€ç»ˆå›ç­”")
                        st.markdown(answer)
                        
                        # æ˜¾ç¤ºé—®é¢˜å›é¡¾
                        with st.expander("æŸ¥çœ‹åŸé—®é¢˜"):
                            st.info(user_query)
                
                except ValueError as e:
                    st.error(f"é…ç½®é”™è¯¯: {str(e)}")
                except Exception as e:
                    st.error(f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}")
        
        # ä½¿ç”¨è¯´æ˜
        with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
            st.markdown("""
            ### ä½¿ç”¨æ­¥éª¤
            
            1. **é…ç½®ç¯å¢ƒå˜é‡**ï¼šå¤åˆ¶ `.env.example` ä¸º `.env`ï¼Œå¡«å…¥æ‚¨çš„ API é…ç½®
            2. **ä¸Šä¼ æ–‡ä»¶**ï¼šæ”¯æŒ txtã€pdfã€markdown æ ¼å¼
            3. **è¾“å…¥é—®é¢˜**ï¼šåœ¨é—®ç­”åŒºåŸŸè¾“å…¥æ‚¨æƒ³äº†è§£çš„é—®é¢˜
            4. **ç”Ÿæˆå›ç­”**ï¼šç‚¹å‡»æŒ‰é’®ï¼Œç³»ç»Ÿå°†æ£€ç´¢ç›¸å…³å†…å®¹å¹¶ç”Ÿæˆç­”æ¡ˆ
            
            ### æ”¯æŒçš„å›½å†…å¤§æ¨¡å‹
            
            - **DeepSeek**: `https://api.deepseek.com`
            - **Moonshot (Kimi)**: `https://api.moonshot.cn/v1`
            - **é€šä¹‰åƒé—®**: `https://dashscope.aliyuncs.com/compatible-mode/v1`
            - **æ™ºè°± GLM4**: `https://open.bigmodel.cn/api/paas/v4`
            
            ### æ³¨æ„äº‹é¡¹
            
            - è¯·ç¡®ä¿ API Key é…ç½®æ­£ç¡®
            - æ–‡ä»¶ä¸Šä¼ åä¼šè‡ªåŠ¨è¿›å…¥å‘é‡åº“
            - å¯ä»¥é€šè¿‡å·¦ä¾§æ æ¸…ç©ºå‘é‡åº“
            """)


if __name__ == "__main__":
    main()
