"""
è‡ªåŠ¨åˆ‡ç‰‡ç­–ç•¥é€‰æ‹©å™¨
æ ¹æ®æ–‡æœ¬ç»“æ„è‡ªåŠ¨é€‰æ‹©æœ€ä½³åˆ‡ç‰‡ç­–ç•¥
"""

import re
from typing import Dict, Tuple, Any


def analyze_structure(text: str) -> Dict[str, Any]:
    """
    åˆ†ææ–‡æœ¬ç»“æ„ç‰¹å¾
    
    Args:
        text: åŸå§‹æ–‡æœ¬
    
    Returns:
        åŒ…å«å„é¡¹ç‰¹å¾çš„å­—å…¸
    """
    if not text or not text.strip():
        return {
            "title_ratio": 0,
            "avg_para_len": 0,
            "para_std": 0,
            "sentence_count": 0,
            "line_count": 0,
            "sentence_density": 0,
            "total_chars": 0
        }
    
    lines = text.split('\n')
    lines = [line.strip() for line in lines if line.strip()]
    line_count = len(lines)
    
    if line_count == 0:
        return {
            "title_ratio": 0,
            "avg_para_len": 0,
            "para_std": 0,
            "sentence_count": 0,
            "line_count": 0,
            "sentence_density": 0,
            "total_chars": 0
        }
    
    # æ ‡é¢˜æ£€æµ‹æ¨¡å¼ï¼ˆMarkdown æ ‡é¢˜ã€æ•°å­—ç¼–å·æ ‡é¢˜ã€ä¸­æ–‡æ ‡é¢˜ç­‰ï¼‰
    title_patterns = [
        r'^#{1,6}\s+',           # Markdown æ ‡é¢˜
        r'^\d+[\.\ã€]\s*\S',     # æ•°å­—ç¼–å· (1. æˆ– 1ã€)
        r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+[ç« èŠ‚æ¡æ¬¾]',  # ä¸­æ–‡ç« èŠ‚
        r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[\.\ã€\s]',        # ä¸­æ–‡æ•°å­—ç¼–å·
        r'^[A-Z][A-Z\s]{2,}$',   # å…¨å¤§å†™æ ‡é¢˜
        r'^\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+\)',           # æ‹¬å·ç¼–å·
    ]
    
    title_count = 0
    for line in lines:
        for pattern in title_patterns:
            if re.match(pattern, line):
                title_count += 1
                break
    
    title_ratio = title_count / line_count if line_count > 0 else 0
    
    # æ®µè½é•¿åº¦ç»Ÿè®¡
    para_lengths = [len(line) for line in lines]
    avg_para_len = sum(para_lengths) / len(para_lengths) if para_lengths else 0
    
    # æ®µè½é•¿åº¦æ ‡å‡†å·®
    if len(para_lengths) > 1:
        mean = avg_para_len
        variance = sum((x - mean) ** 2 for x in para_lengths) / len(para_lengths)
        para_std = variance ** 0.5
    else:
        para_std = 0
    
    # å¥å­ç»Ÿè®¡ï¼ˆä¸­è‹±æ–‡å¥å­ç»“æŸç¬¦ï¼‰
    sentence_endings = re.findall(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
    sentence_count = len(sentence_endings)
    
    # å¥å­å¯†åº¦
    sentence_density = sentence_count / line_count if line_count > 0 else 0
    
    # æ€»å­—ç¬¦æ•°
    total_chars = len(text)
    
    return {
        "title_ratio": title_ratio,
        "avg_para_len": avg_para_len,
        "para_std": para_std,
        "sentence_count": sentence_count,
        "line_count": line_count,
        "sentence_density": sentence_density,
        "total_chars": total_chars
    }


def detect_type(features: Dict[str, Any]) -> str:
    """
    æ ¹æ®ç‰¹å¾è¯†åˆ«æ–‡ä½“ç±»å‹
    
    Args:
        features: analyze_structure è¿”å›çš„ç‰¹å¾å­—å…¸
    
    Returns:
        æ–‡ä½“ç±»å‹: structured, long_form, fragment, legal, normal
    """
    title_ratio = features.get("title_ratio", 0)
    avg_para_len = features.get("avg_para_len", 0)
    para_std = features.get("para_std", 0)
    sentence_density = features.get("sentence_density", 0)
    total_chars = features.get("total_chars", 0)
    
    # æ³•å¾‹/åˆåŒæ–‡æ¡£ç‰¹å¾ï¼šæ®µè½è¾ƒé•¿ã€ç»“æ„åŒ–ç¨‹åº¦é«˜ã€å¥å­å¯†åº¦é«˜
    if title_ratio > 0.1 and avg_para_len > 100 and sentence_density > 2:
        return "legal"
    
    # ç»“æ„åŒ–æ–‡æ¡£ï¼ˆæŠ€æœ¯æ–‡æ¡£/æ ‡é¢˜å¤šï¼‰ï¼šæ ‡é¢˜å¯†åº¦é«˜
    if title_ratio > 0.15:
        return "structured"
    
    # ç¢ç‰‡åŒ–æ–‡æ¡£ï¼ˆFAQ/å¯¹è¯/çŸ­å¥å¤šï¼‰ï¼šå¹³å‡æ®µè½çŸ­ã€å¥å­å¯†åº¦ä½
    if avg_para_len < 50 and sentence_density < 1.5:
        return "fragment"
    
    # é•¿æ–‡æ¡£ï¼ˆè®ºæ–‡/ä¹¦ç±ï¼‰ï¼šæ€»å­—ç¬¦å¤šã€æ®µè½é•¿ã€æ ‡å‡†å·®å¤§
    if total_chars > 5000 and avg_para_len > 150:
        return "long_form"
    
    # é»˜è®¤æ™®é€šæ–‡æ¡£
    return "normal"


def choose_chunk_strategy(text: str) -> Tuple[str, Dict[str, Any]]:
    """
    æ ¹æ®æ–‡æœ¬è‡ªåŠ¨é€‰æ‹©æœ€ä½³åˆ‡ç‰‡ç­–ç•¥
    
    Args:
        text: åŸå§‹æ–‡æœ¬
    
    Returns:
        (strategy_name, params) å…ƒç»„
        strategy_name: heading_chunk, sliding_window, sentence_chunk, 
                      semantic_llm_chunk, paragraph_chunk
        params: ç­–ç•¥å‚æ•°å­—å…¸
    """
    features = analyze_structure(text)
    doc_type = detect_type(features)
    
    # æ ¹æ®æ–‡ä½“ç±»å‹é€‰æ‹©ç­–ç•¥
    if doc_type == "structured":
        # ç»“æ„åŒ–æ–‡æ¡£ï¼šæŒ‰æ ‡é¢˜åˆ‡åˆ†
        return ("heading_chunk", {"chunk_size": 800})
    
    elif doc_type == "long_form":
        # é•¿æ–‡æ¡£ï¼šæ»‘åŠ¨çª—å£ï¼Œè¾ƒå¤§ chunkï¼Œè¾ƒå¤šé‡å 
        return ("sliding_window", {"chunk_size": 600, "overlap": 150})
    
    elif doc_type == "fragment":
        # ç¢ç‰‡åŒ–æ–‡æ¡£ï¼šæŒ‰å¥å­åˆ‡åˆ†
        return ("sentence_chunk", {"min_len": 100, "max_len": 500})
    
    elif doc_type == "legal":
        # æ³•å¾‹æ–‡æ¡£ï¼šè¯­ä¹‰åˆ‡åˆ†ï¼ˆè°ƒç”¨ LLMï¼‰
        return ("semantic_llm_chunk", {"max_chunk": 1000})
    
    else:
        # æ™®é€šæ–‡æ¡£ï¼šæ®µè½åˆ‡åˆ†
        return ("paragraph_chunk", {"chunk_size": 500, "overlap": 50})


def get_strategy_description(strategy: str) -> str:
    """
    è·å–ç­–ç•¥çš„ä¸­æ–‡æè¿°
    
    Args:
        strategy: ç­–ç•¥åç§°
    
    Returns:
        ç­–ç•¥çš„ä¸­æ–‡æè¿°
    """
    descriptions = {
        "heading_chunk": "ğŸ“‘ æ ‡é¢˜åˆ‡åˆ†ï¼ˆé€‚åˆæŠ€æœ¯æ–‡æ¡£ï¼‰",
        "sliding_window": "ğŸªŸ æ»‘åŠ¨çª—å£ï¼ˆé€‚åˆé•¿æ–‡æ¡£ï¼‰",
        "sentence_chunk": "ğŸ“ å¥å­åˆ‡åˆ†ï¼ˆé€‚åˆFAQ/å¯¹è¯ï¼‰",
        "semantic_llm_chunk": "ğŸ§  è¯­ä¹‰åˆ‡åˆ†ï¼ˆé€‚åˆæ³•å¾‹æ–‡æ¡£ï¼‰",
        "paragraph_chunk": "ğŸ“„ æ®µè½åˆ‡åˆ†ï¼ˆé€šç”¨ç­–ç•¥ï¼‰"
    }
    return descriptions.get(strategy, strategy)
