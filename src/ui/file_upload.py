"""
æ–‡ä»¶ä¸Šä¼  UI ç»„ä»¶
åŒ…å«æ–‡ä»¶ä¸Šä¼ å’Œ JSON æ•°æ®å¯¼å…¥åŠŸèƒ½
"""

import streamlit as st
import json

from rag_engine import (
    load_env,
    split_text_by_strategy,
    embed_texts,
    add_to_vector_db,
    add_to_bm25_index
)
from src.utils import read_file
from src.rag.chunker import choose_chunk_strategy, get_strategy_description


def render_file_upload():
    """æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ"""
    st.subheader("ğŸ“¤ ä¸Šä¼ æ–‡ä»¶")
    
    uploaded_files = st.file_uploader(
        "é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
        type=["txt", "pdf", "md", "markdown", "jpg", "jpeg", "png"],
        accept_multiple_files=True,
        help="ä¸Šä¼ çš„æ–‡ä»¶å°†è‡ªåŠ¨åˆ‡åˆ†å¹¶å­˜å…¥å‘é‡åº“ï¼ˆå›¾ç‰‡å°†é€šè¿‡ OCR è¯†åˆ«ï¼‰"
    )
    
    if uploaded_files:
        load_env()
        with st.spinner("æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶..."):
            for uploaded_file in uploaded_files:
                try:
                    file_content = uploaded_file.read()
                    text = read_file(uploaded_file.name, file_content)
                    
                    if text:
                        strategy, params = choose_chunk_strategy(text)
                        st.session_state.chunk_strategy = strategy
                        st.session_state.chunk_params = params
                        
                        chunks = split_text_by_strategy(text, strategy, params)
                        
                        if chunks:
                            embeddings = embed_texts(chunks)
                            add_to_vector_db(chunks, embeddings)
                            add_to_bm25_index(chunks)
                            
                            strategy_desc = get_strategy_description(strategy)
                            st.success(f"âœ… {uploaded_file.name}: æˆåŠŸæ·»åŠ  {len(chunks)} ä¸ª chunksï¼ˆ{strategy_desc}ï¼‰")
                            st.info(f"ğŸ“Š å·²åŒæ­¥åˆ°å‘é‡åº“å’Œ BM25 ç´¢å¼•")
                        else:
                            st.warning(f"âš ï¸ {uploaded_file.name}: æ–‡ä»¶å†…å®¹ä¸ºç©º")
                    else:
                        st.error(f"âŒ {uploaded_file.name}: ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
                
                except Exception as e:
                    st.error(f"âŒ {uploaded_file.name}: å¤„ç†å¤±è´¥ - {str(e)}")
    
    # å¯¼å…¥é¢„å¤„ç†æ•°æ®
    st.subheader("ğŸ“¥ å¯¼å…¥é¢„å¤„ç†æ•°æ®")
    imported_file = st.file_uploader(
        "å¯¼å…¥ JSON æ ¼å¼çš„ chunks",
        type=["json"],
        key="import_chunks_file",
        help="æ”¯æŒä» pdf-rag-pipeline å¯¼å‡ºçš„ chunks_for_streamlit.json"
    )
    
    if imported_file:
        if 'imported_chunks' not in st.session_state or st.session_state.get('imported_file_name') != imported_file.name:
            try:
                content = imported_file.read().decode('utf-8')
                chunks = json.loads(content)
                if isinstance(chunks, list) and chunks:
                    st.session_state.imported_chunks = chunks
                    st.session_state.imported_file_name = imported_file.name
                    st.info(f"ğŸ“„ å·²åŠ è½½ {len(chunks)} ä¸ª chunksï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å¯¼å…¥")
                else:
                    st.error("âŒ JSON æ ¼å¼é”™è¯¯ï¼Œéœ€è¦æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨")
            except Exception as e:
                st.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        else:
            st.info(f"ğŸ“„ å·²åŠ è½½ {len(st.session_state.imported_chunks)} ä¸ª chunksï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å¯¼å…¥")
        
        if st.button("ğŸš€ å¼€å§‹å¯¼å…¥åˆ°å‘é‡åº“", key="start_import"):
            chunks = st.session_state.imported_chunks
            load_env()
            
            batch_size = 50
            total_added = 0
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                for i in range(0, len(chunks), batch_size):
                    batch = chunks[i:i+batch_size]
                    status_text.text(f"å¤„ç†ä¸­: {min(i+batch_size, len(chunks))}/{len(chunks)} chunks...")
                    
                    embeddings = embed_texts(batch)
                    add_to_vector_db(batch, embeddings)
                    add_to_bm25_index(batch)
                    total_added += len(batch)
                    
                    progress_bar.progress(min(total_added / len(chunks), 1.0))
                
                progress_bar.empty()
                status_text.empty()
                del st.session_state.imported_chunks
                del st.session_state.imported_file_name
                st.success(f"âœ… æˆåŠŸå¯¼å…¥ {total_added} ä¸ª chunksï¼ˆå·²åŒæ­¥åˆ°å‘é‡åº“å’Œ BM25 ç´¢å¼•ï¼‰")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}ï¼ˆå·²å¯¼å…¥ {total_added} ä¸ªï¼‰")
    
    st.markdown("---")
